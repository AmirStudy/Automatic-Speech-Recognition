
# Describe valid chars used to convert transcript into sequence of
# labels and vice versa.
alphabet:
  file_path: models/pl/alphabet.txt


# Define how audio files are processing.
features_extractor:
  numcep: 26
  winlen: 0.032
  winstep: 0.02
  winfunc: hamming


# Custom architecture can be created using `deepspeech-custom`.
model:
  name: deepspeech
  units: 2048


# The available optimizers are specified in: `get_optimizer` and
# come from `keras.optimizers` module.
optimizer:
  name: adam
  lr: 0.001
  beta_1: 0.9
  beta_2: 0.999
  epsilon: 0.00000001


# Set callbacks to get a view on internal states and statistics of the model
# during training.
callbacks:
- name: TerminateOnNaN

- name: ResultKeeper
  file_name: results.bin

- name: CustomModelCheckpoint
  log_dir: checkpoints

- name: CustomTensorBoard
  log_dir: tensorboard

- name: LearningRateScheduler
  # Around 8% at epoch 25
  k: 0.1
  verbose: 1

- name: CustomEarlyStopping
  mini_targets:
    5: 200
    10: 100
  monitor: val_loss
  patience: 3


# Define method of decoding probabilities into transcription
decoder:
  name: tensorflow
  beam_size: 1024
